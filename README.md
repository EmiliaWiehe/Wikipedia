# Wikipedia

- Identify 5 categories of pages on wikipedia, for each category choose 300 items.

With a python script:
- load the pages,
- preprocess them (*)
- insert them in a dataframe (save the dataframe in a CSV file and use it later for subsequent loads)
- Create statistics (frequency and word length, for example) on the pages and show them with different types of visualization
- Calculate the distance between pages in the same category and between different categories
- Classify the pages, using the categories as labels.
- Check the wikipedia categorization or any deviations with a clustering method and in this case analyze the probable causes